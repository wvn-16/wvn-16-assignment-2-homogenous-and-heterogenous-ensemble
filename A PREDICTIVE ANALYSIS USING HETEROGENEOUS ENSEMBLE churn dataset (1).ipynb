{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05301af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "# Loading dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\user\\Downloads\\Churn_Modelling (1).csv\")\n",
    "\n",
    "\n",
    "# Removing unnecessary columns\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Encoding categorical variables\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "data = ct.fit_transform(data)\n",
    "\n",
    "# Removing one dummy variable to avoid the dummy variable trap\n",
    "data = data[:, 1:]\n",
    "\n",
    "# Splitting dataset into training and testing sets\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Defining base models\n",
    "rfc = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "\n",
    "# Defining ensemble model\n",
    "estimators = [('rf', rfc), ('gb', gbc)]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "\n",
    "# Training and evaluating ensemble model\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# First, we need to import the necessary libraries and load the dataset.\n",
    "# Now, we will perform some data preprocessing steps.\n",
    "# Firstly, we will remove the unnecessary columns such as RowNumber, CustomerId, and Surname.\n",
    "# Then, we will convert the string datatype columns Gender and Geography into float datatype using LabelEncoder and OneHotEncoder respectively.\n",
    "# Next, we will split the dataset into training and testing sets, and perform feature scaling using StandardScaler.\n",
    "# Now, we will define the base models that we will use in our ensemble. We will use RandomForestClassifier, GradientBoostingClassifier, and XGBClassifier as our base models.\n",
    "# We will now define our ensemble model. We will use the VotingClassifier from sklearn.ensemble to combine our base models.\n",
    "# Finally, we will train our ensemble model on the training set and evaluate its performance on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f30e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\user\\Downloads\\Churn_Modelling (1).csv\")\n",
    "\n",
    "# Preprocessing the data\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "data = pd.get_dummies(data, columns=['Geography'])\n",
    "sc = StandardScaler()\n",
    "data[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']] = sc.fit_transform(data[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']])\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X = data.drop(['Exited'], axis=1)\n",
    "y = data['Exited']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a heterogeneous ensemble model\n",
    "clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf2 = GradientBoostingClassifier(random_state=1)\n",
    "clf3 = LogisticRegression(random_state=1)\n",
    "clf4 = GaussianNB()\n",
    "clf5 = SVC(kernel='linear', probability=True, random_state=1)\n",
    "clf6 = SVC(kernel='rbf', probability=True, random_state=1)\n",
    "clf7 = SVC(kernel='poly', probability=True, random_state=1)\n",
    "eclf = VotingClassifier(estimators=[('rf', clf1), ('gb', clf2), ('lr', clf3), ('gnb', clf4), ('svc1', clf5), ('svc2', clf6), ('svc3', clf7)], voting='soft')\n",
    "\n",
    "# Training and evaluating the model\n",
    "eclf.fit(X_train, y_train)\n",
    "y_pred = eclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizing the results\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "\n",
    "scores = cross_val_score(eclf, X, y, cv=10)\n",
    "sns.boxplot(y=scores)\n",
    "plt.title('Cross-validation scores')\n",
    "plt.show()\n",
    "\n",
    "# Getting the predicted probabilities\n",
    "y_score = eclf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Plotting the Precision-Recall curve for the ensemble model\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "pr_auc = auc(recall, precision)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, lw=2, label='Precision-Recall curve (AUC = %0.2f)' % pr_auc)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Accuracy score:', accuracy)\n",
    "print('Cross-validation scores:', scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf05d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683311a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc04f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
